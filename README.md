# OpenIssuesForML
===============<br>
record machine learning algorithm open issues and answers

|Author|Ximitiejiang|
|---|---
|E-mail|ximitiejiang@163.com

### Q_线性回归算法：如何计算l1,l2范数？两者的功能有什么区别？
1. l1范数
2. l2范数
3. 两者的区别：l1范数是lambda*(abs(distance))，l2范数是lambda*(distance**2)

### Q_决策树算法：怎么计算信息熵和信息增益？一个骰子抛6次信息熵是多少？
信息熵Ent(D) = -sum(Pk * logPk)
所以对于一个骰子来说，Ent(D) = -6*(1/6 * log1/6) = 2.6 bit


### Q_决策树算法：决策树ID3算法为什么不能使用连续特征，如何解决？
1. 分类问题：可以用ID3或者CART
    * ID3决策树在做子数据集划分的时候采用的是按照最优特征的数值类型来划分的，
    有多少类就划分多少个子集，如果用连续特征，就会每个值划分一个数据集，导致模型基本没有泛化能力
    而CART决策树回归在做子数据集划分采用的是二分法，按照取值，每次都划分成2个子集，非常有利于连续特征的划分。
    而对于多类型离散特征的划分，需要对多类型特征排列组合多次划分，则相比于ID3需要更多次划分和计算量

2. 回归问题：只能用CART
    * 由于数据是连续的，没法计算信息熵或者gini指数，需要采用其他办法评估最优特征。可采用均方误差和来评估。


### Q_朴素贝叶斯：如果有部分分类的概率等于0怎么办？比如一个数据实例：？？？
如果某个概率为0会导致计算分母为0的错误，需要通过拉普拉斯平滑，在分母增加一个N，分子增加一个1

### Q_adaBoost：为什么boost要用多个弱分类器，而不用强分类器？

### Q_adaBoost：偏差与方差的关系和区别，两者的权衡是什么？

### Q_降维算法：降维有什么好处，有哪些降维的方法？
1. 降维的好处：
    * 减少存储空间，加快计算速度，去除冗余特征，便于可视化
2. 降维的方法：
    * 去除缺失值过多的列
    * 

### Q_数据处理：如何处理特征向量的缺失值？
特征向量缺失值处理方法有如下几种：
1. 缺失值较多：
    超过20%，则考虑直接舍弃该特征
2. 缺失值较少：
    * 用0值填充
        ```python
        train.isnull()
        train.fillna(0)
        ```
    * 用平均值填充
    * 用众数填充
    * 用插值法填充
    * 用随机森林法预测：
        > 将数据分为有值和缺失值2份，对有值的数据采用随机森林拟合，然后对有缺失值的数据进行预测，用预测的值来填充。

### Q_推荐算法：余弦相似和欧式距离有什么关系和区别？